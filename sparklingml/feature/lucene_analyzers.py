#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# DO NOT MODIFY THIS FILE!
# It was auto generated by LuceneanalyzerGenerators

from __future__ import unicode_literals

from pyspark import keyword_only
from pyspark.rdd import ignore_unicode_prefix
from pyspark.ml import Model
from pyspark.ml.param import *
# The shared params aren't really intended to be public currently..
from pyspark.ml.param.shared import *
from pyspark.ml.util import *

from sparklingml.java_wrapper_ml import *
from sparklingml.param.shared import HasStopwords, HasStopwordCase


class ArabicAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ArabicAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ArabicAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(ArabicAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class BulgarianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = BulgarianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "BulgarianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(BulgarianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class BrazilianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = BrazilianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "BrazilianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(BrazilianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class CatalanAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = CatalanAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "CatalanAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(CatalanAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class CJKAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = CJKAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "CJKAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(CJKAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class SoraniAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = SoraniAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "SoraniAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(SoraniAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class StopAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = StopAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "StopAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(StopAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class CzechAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = CzechAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "CzechAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(CzechAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class DanishAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = DanishAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "DanishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(DanishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class GermanAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = GermanAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "GermanAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(GermanAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class GreekAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = GreekAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "GreekAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(GreekAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class EnglishAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = EnglishAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "EnglishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(EnglishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class SpanishAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = SpanishAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "SpanishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(SpanishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class BasqueAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = BasqueAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "BasqueAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(BasqueAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class PersianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = PersianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "PersianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(PersianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class FinnishAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = FinnishAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "FinnishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(FinnishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class FrenchAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = FrenchAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "FrenchAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(FrenchAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class IrishAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = IrishAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "IrishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(IrishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class GalicianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = GalicianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "GalicianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(GalicianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class HindiAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = HindiAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "HindiAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(HindiAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class HungarianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = HungarianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "HungarianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(HungarianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class ArmenianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ArmenianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ArmenianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(ArmenianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class IndonesianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = IndonesianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "IndonesianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(IndonesianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class ItalianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ItalianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ItalianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(ItalianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class LithuanianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = LithuanianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "LithuanianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(LithuanianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class LatvianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = LatvianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "LatvianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(LatvianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class NorwegianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = NorwegianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "NorwegianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(NorwegianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class PortugueseAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = PortugueseAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "PortugueseAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(PortugueseAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class RomanianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = RomanianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "RomanianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(RomanianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class RussianAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = RussianAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "RussianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(RussianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class ClassicAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ClassicAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ClassicAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(ClassicAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class StandardAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = StandardAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "StandardAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(StandardAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class UAX29URLEmailAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = UAX29URLEmailAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "UAX29URLEmailAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(UAX29URLEmailAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class SwedishAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = SwedishAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "SwedishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(SwedishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class ThaiAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ThaiAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ThaiAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(ThaiAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

class TurkishAnalyzerLucene(SparklingJavaTransformer, HasStopwords,
                            HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = TurkishAnalyzerLucene()
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "TurkishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, stopwords=None, stopwordCase=False):
        """
        __init__(self, stopwords=None, stopwordCase=False)
        """
        super(TurkishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase = False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, stopwords=None, stopwordCase=False):
        """
        setParams(stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)

if __name__ == "__main__":
    import doctest
    doctest.testmod(optionflags=doctest.ELLIPSIS)
